{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 231,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.3088803088803089,
      "grad_norm": 281.0000915527344,
      "learning_rate": 9.727272727272728e-06,
      "loss": 57.3981,
      "step": 10
    },
    {
      "epoch": 0.6177606177606177,
      "grad_norm": 271.3963317871094,
      "learning_rate": 9.424242424242425e-06,
      "loss": 51.9904,
      "step": 20
    },
    {
      "epoch": 0.9266409266409267,
      "grad_norm": 262.8434753417969,
      "learning_rate": 9.121212121212122e-06,
      "loss": 45.4814,
      "step": 30
    },
    {
      "epoch": 1.2162162162162162,
      "grad_norm": 223.73583984375,
      "learning_rate": 8.818181818181819e-06,
      "loss": 35.2865,
      "step": 40
    },
    {
      "epoch": 1.525096525096525,
      "grad_norm": 198.2235565185547,
      "learning_rate": 8.515151515151517e-06,
      "loss": 30.6161,
      "step": 50
    },
    {
      "epoch": 1.833976833976834,
      "grad_norm": 163.6141815185547,
      "learning_rate": 8.212121212121212e-06,
      "loss": 22.4484,
      "step": 60
    },
    {
      "epoch": 2.1235521235521237,
      "grad_norm": 143.02053833007812,
      "learning_rate": 7.909090909090909e-06,
      "loss": 14.9141,
      "step": 70
    },
    {
      "epoch": 2.4324324324324325,
      "grad_norm": 108.226806640625,
      "learning_rate": 7.606060606060606e-06,
      "loss": 10.5039,
      "step": 80
    },
    {
      "epoch": 2.741312741312741,
      "grad_norm": 74.7945785522461,
      "learning_rate": 7.303030303030304e-06,
      "loss": 7.0067,
      "step": 90
    },
    {
      "epoch": 3.030888030888031,
      "grad_norm": 47.08009719848633,
      "learning_rate": 7e-06,
      "loss": 3.9514,
      "step": 100
    },
    {
      "epoch": 3.33976833976834,
      "grad_norm": 33.001243591308594,
      "learning_rate": 6.6969696969696975e-06,
      "loss": 2.6314,
      "step": 110
    },
    {
      "epoch": 3.6486486486486487,
      "grad_norm": 23.31425666809082,
      "learning_rate": 6.393939393939394e-06,
      "loss": 1.8992,
      "step": 120
    },
    {
      "epoch": 3.9575289575289574,
      "grad_norm": 21.417144775390625,
      "learning_rate": 6.090909090909092e-06,
      "loss": 1.581,
      "step": 130
    },
    {
      "epoch": 4.2471042471042475,
      "grad_norm": 21.618772506713867,
      "learning_rate": 5.787878787878788e-06,
      "loss": 1.2826,
      "step": 140
    },
    {
      "epoch": 4.555984555984556,
      "grad_norm": 16.011531829833984,
      "learning_rate": 5.484848484848485e-06,
      "loss": 1.2211,
      "step": 150
    },
    {
      "epoch": 4.864864864864865,
      "grad_norm": 14.705194473266602,
      "learning_rate": 5.181818181818182e-06,
      "loss": 1.0764,
      "step": 160
    },
    {
      "epoch": 5.154440154440154,
      "grad_norm": 12.688835144042969,
      "learning_rate": 4.878787878787879e-06,
      "loss": 0.8571,
      "step": 170
    },
    {
      "epoch": 5.463320463320463,
      "grad_norm": 15.087742805480957,
      "learning_rate": 4.575757575757576e-06,
      "loss": 0.9437,
      "step": 180
    },
    {
      "epoch": 5.772200772200772,
      "grad_norm": 13.917604446411133,
      "learning_rate": 4.272727272727273e-06,
      "loss": 0.8365,
      "step": 190
    },
    {
      "epoch": 6.061776061776062,
      "grad_norm": 10.90261173248291,
      "learning_rate": 3.96969696969697e-06,
      "loss": 0.7275,
      "step": 200
    },
    {
      "epoch": 6.370656370656371,
      "grad_norm": 10.710686683654785,
      "learning_rate": 3.6666666666666666e-06,
      "loss": 0.7414,
      "step": 210
    },
    {
      "epoch": 6.67953667953668,
      "grad_norm": 8.444836616516113,
      "learning_rate": 3.3636363636363637e-06,
      "loss": 0.7107,
      "step": 220
    },
    {
      "epoch": 6.988416988416988,
      "grad_norm": 8.521015167236328,
      "learning_rate": 3.0606060606060605e-06,
      "loss": 0.6026,
      "step": 230
    }
  ],
  "logging_steps": 10,
  "max_steps": 330,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.460157924829798e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
